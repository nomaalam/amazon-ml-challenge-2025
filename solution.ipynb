{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2771e46-2213-4e23-a645-98150caa03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "# Ensure you have AutoTokenizer, AutoImageProcessor\n",
    "from transformers import AutoTokenizer, AutoImageProcessor, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # New import for loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f969f03-53c2-46a7-931e-451df31b9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src2.utils import download_images, smape\n",
    "from src2.model import MultiModalPricer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ce3b412-c101-4739-8c81-73f7c6f1e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdfddd3b-0095-47ae-8871-27839bb80f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "IMAGE_MODEL_NAME = \"google/vit-base-patch16-224-in21k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef8507d3-77c5-4f34-ba5a-303bc4085408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimization Hyperparameters ---\n",
    "NUM_EPOCHS = 7\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT_SIZE = 0.15 # Define split size for data loading\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Tiered Learning Rates (CRITICAL for fine-tuning)\n",
    "LR_ENCODERS = 3e-5   # 0.00003: Small step for pre-trained weights\n",
    "LR_HEAD = 3e-4       # 0.0003: 10x higher for new, randomly initialized layers\n",
    "\n",
    "# Optimizer Settings\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.05  # 5% of training steps for learning rate warm-up\n",
    "\n",
    "# Loss Function Weighting\n",
    "SMAPE_WEIGHT = 0.8   # Weight for the SMAPE component in the Hybrid Loss\n",
    "HUBER_DELTA = 1.0    # Delta for the Huber Loss (nn.SmoothL1Loss)\n",
    "\n",
    "# Model Settings\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Ensure the training loop patience matches the hyperparameter strategy\n",
    "EARLY_STOPPING_PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b3ed9b1-2f46-4fe4-961c-e129fe2c5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = 'dataset/train.csv'\n",
    "TEST_CSV_PATH = 'dataset/test.csv'\n",
    "TRAIN_IMAGE_DIR = 'images2/train/'\n",
    "TEST_IMAGE_DIR = 'images2/test/'\n",
    "MODEL_SAVE_PATH = 'best_model_01_hyper.pth'\n",
    "SUBMISSION_PATH = 'test_out_01_hyper.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36243c53-65ca-45b8-a8a7-3084a1ee5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Hybrid Loss Function (New Cell) ---\n",
    "\n",
    "class SmoothSmapeLoss(nn.Module):\n",
    "    \"\"\"Calculates a differentiable approximation of the SMAPE metric on the original price scale.\"\"\"\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred_log, y_true_log):\n",
    "        # 1. Inverse transform back to original price scale (Price = exp(log_price) - 1)\n",
    "        y_pred_orig = torch.expm1(y_pred_log)\n",
    "        y_true_orig = torch.expm1(y_true_log)\n",
    "        \n",
    "        # Prices must be non-negative\n",
    "        y_pred_orig = F.relu(y_pred_orig)\n",
    "        \n",
    "        # Numerator: Absolute difference\n",
    "        numerator = torch.abs(y_pred_orig - y_true_orig)\n",
    "        \n",
    "        # Denominator: Average of absolute true and predicted values + epsilon for stability\n",
    "        denominator = (torch.abs(y_true_orig) + torch.abs(y_pred_orig)) / 2.0\n",
    "        \n",
    "        # SMAPE loss (ratio)\n",
    "        loss = numerator / (denominator + self.epsilon)\n",
    "        \n",
    "        return torch.mean(loss)\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Loss = (SMAPE_WEIGHT * SmoothSmapeLoss) + ((1 - SMAPE_WEIGHT) * HuberLoss)\n",
    "    \"\"\"\n",
    "    def __init__(self, huber_delta=HUBER_DELTA, smape_weight=SMAPE_WEIGHT):\n",
    "        super().__init__()\n",
    "        self.smape_loss = SmoothSmapeLoss()\n",
    "        # Huber Loss (SmoothL1Loss) applied to the stable, log-transformed data\n",
    "        self.huber_loss = nn.SmoothL1Loss(reduction='mean', beta=huber_delta)\n",
    "        self.smape_weight = smape_weight\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        smape_loss = self.smape_loss(y_pred, y_true)\n",
    "        huber_loss = self.huber_loss(y_pred, y_true) \n",
    "        \n",
    "        return self.smape_weight * smape_loss + (1 - self.smape_weight) * huber_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba0f78aa-5fa1-40b9-a194-ad491fec2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Performing feature engineering...\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading (Cell 8) ---\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "# --- Feature Engineering Functions (Cell 10) ---\n",
    "def extract_ipq(text):\n",
    "    \"\"\"Extracts Item Pack Quantity (IPQ) from text using regex.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return 1.0\n",
    "    # Look for patterns like \"Pack of X\", \"IPQ: X\", etc.\n",
    "    match = re.search(r'(?:pack of|ipq:?|pk)\\s*(\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 1.0 # Default to 1 if no pack size is found\n",
    "\n",
    "# --- Apply Feature Engineering (Cell 11) ---\n",
    "print(\"Performing feature engineering...\")\n",
    "train_df['ipq'] = train_df['catalog_content'].apply(extract_ipq)\n",
    "test_df['ipq'] = test_df['catalog_content'].apply(extract_ipq)\n",
    "\n",
    "# --- Target Transformation (Cell 13) ---\n",
    "train_df['log_price'] = np.log1p(train_df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "016d1f76-e542-4988-9684-e5dad15f6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sample_id                                    catalog_content  \\\n",
      "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
      "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
      "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
      "3      55858  Item Name: Judeeâ€™s Blue Cheese Powder 11.25 oz...   \n",
      "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
      "\n",
      "                                          image_link  price  ipq  log_price  \n",
      "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  6.0   1.773256  \n",
      "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  4.0   2.647592  \n",
      "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  6.0   1.088562  \n",
      "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  1.0   3.444895  \n",
      "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  1.0   4.211979  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b47f2726-fbbb-4880-99a6-b86ae7234f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Custom PyTorch Dataset (Cell 19 - Modified) ---\n",
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, tokenizer, image_processor, is_train=True):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_processor = image_processor\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Text data\n",
    "        text = row['catalog_content'] if isinstance(row['catalog_content'], str) else \"\"\n",
    "        # Use MAX_SEQ_LENGTH constant\n",
    "        text_inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=MAX_SEQ_LENGTH, return_tensors=\"pt\")\n",
    "        \n",
    "        # Image data\n",
    "        image_path = os.path.join(self.image_dir, f\"{row['sample_id']}.jpg\")\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except (IOError, FileNotFoundError):\n",
    "            # Use a placeholder black image if the original is missing/corrupt\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        image_inputs = self.image_processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # Extra features\n",
    "        ipq = torch.tensor(row['ipq'], dtype=torch.float32)\n",
    "\n",
    "        # Prepare output dictionary\n",
    "        data = {\n",
    "            'input_ids': text_inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': text_inputs['attention_mask'].squeeze(0),\n",
    "            'pixel_values': image_inputs['pixel_values'].squeeze(0),\n",
    "            'ipq': ipq\n",
    "        }\n",
    "        \n",
    "        if self.is_train:\n",
    "            data['target'] = torch.tensor(row['log_price'], dtype=torch.float32)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0effcc17-224c-4164-9406-935bae1c5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Initialize Model and Loss (Cell 24 - Modified) ---\n",
    "model = MultiModalPricer(TEXT_MODEL_NAME, IMAGE_MODEL_NAME).to(DEVICE)\n",
    "\n",
    "# Initialize the Hybrid Loss Function\n",
    "LOSS_FN = HybridLoss(huber_delta=HUBER_DELTA, smape_weight=SMAPE_WEIGHT).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce5328e3-62e6-44b2-bef0-d2bf5ac7662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 14770\n",
      "Warmup steps: 738\n",
      "Encoder LR: 3e-05, Head LR: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# --- New Cell: Tiered Optimizer and Scheduler Setup ---\n",
    "\n",
    "# Calculate total number of training steps for the scheduler\n",
    "total_batches = len(train_loader)\n",
    "num_training_steps = total_batches * NUM_EPOCHS\n",
    "num_warmup_steps = int(num_training_steps * WARMUP_RATIO)\n",
    "\n",
    "\n",
    "# --- TIERED LEARNING RATE SETUP ---\n",
    "# 1. Group parameters by desired learning rate and weight decay\n",
    "param_optimizer = list(model.named_parameters())\n",
    "encoder_params = []\n",
    "head_params = []\n",
    "\n",
    "for n, p in param_optimizer:\n",
    "    # Check for the regression head layers (assumes names contain 'head', 'linear', or 'final')\n",
    "    if any(keyword in n.lower() for keyword in ['head', 'linear', 'final']): \n",
    "        head_params.append(p)\n",
    "    else:\n",
    "        encoder_params.append(p)\n",
    "\n",
    "# 2. Define grouped parameters for the optimizer\n",
    "optimizer_grouped_parameters = [\n",
    "    # Group 1: Encoders (Pre-trained layers - low LR)\n",
    "    {'params': encoder_params, 'weight_decay': WEIGHT_DECAY, 'lr': LR_ENCODERS},\n",
    "    # Group 2: Regression Head (New layers - high LR)\n",
    "    {'params': head_params, 'weight_decay': WEIGHT_DECAY, 'lr': LR_HEAD},\n",
    "]\n",
    "\n",
    "# 3. Initialize AdamW Optimizer\n",
    "optimizer = optim.AdamW(optimizer_grouped_parameters)\n",
    "\n",
    "# 4. Initialize Linear Learning Rate Scheduler with Warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "print(f\"Total training steps: {num_training_steps}\")\n",
    "print(f\"Warmup steps: {num_warmup_steps}\")\n",
    "print(f\"Encoder LR: {LR_ENCODERS}, Head LR: {LR_HEAD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07058f0e-986b-4f69-9387-adc403631079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [30:46<00:00,  1.14it/s, loss=0.6]\n",
      "Epoch 1/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [01:57<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Train Loss: 0.6000, Validation SMAPE: 57.6992%\n",
      " New best model saved with SMAPE: 57.6992%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [37:03<00:00,  1.05s/it, loss=0.476]\n",
      "Epoch 2/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [02:00<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7, Train Loss: 0.4760, Validation SMAPE: 50.6014%\n",
      " New best model saved with SMAPE: 50.6014%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [39:33<00:00,  1.12s/it, loss=0.422]\n",
      "Epoch 3/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [01:58<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7, Train Loss: 0.4218, Validation SMAPE: 47.7256%\n",
      " New best model saved with SMAPE: 47.7256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [39:37<00:00,  1.13s/it, loss=0.371]\n",
      "Epoch 4/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [02:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7, Train Loss: 0.3713, Validation SMAPE: 46.9122%\n",
      " New best model saved with SMAPE: 46.9122%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [39:59<00:00,  1.14s/it, loss=0.328]\n",
      "Epoch 5/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [01:58<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7, Train Loss: 0.3275, Validation SMAPE: 46.6479%\n",
      " New best model saved with SMAPE: 46.6479%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [39:57<00:00,  1.14s/it, loss=0.29]\n",
      "Epoch 6/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [01:58<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7, Train Loss: 0.2898, Validation SMAPE: 46.0416%\n",
      " New best model saved with SMAPE: 46.0416%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2110/2110 [38:48<00:00,  1.10s/it, loss=0.26]\n",
      "Epoch 7/7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235/235 [01:58<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Train Loss: 0.2604, Validation SMAPE: 46.0416%\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Training Loop (Cell 40 - Modified) ---\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "best_val_smape = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # -----------------------------\n",
    "    # ðŸ”¹ Training Phase\n",
    "    # -----------------------------\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training]\")\n",
    "    \n",
    "    for batch in train_pbar:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "        ipq = batch['ipq'].to(DEVICE)\n",
    "        targets = batch['target'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, pixel_values, ipq)\n",
    "        \n",
    "        # Use the Hybrid Loss\n",
    "        loss = LOSS_FN(outputs.squeeze(), targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Optional: Gradient Clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step() # <<< CRITICAL: Update the learning rate\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_pbar.set_postfix({'loss': running_loss / (len(train_pbar) + 1e-8)})\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # -----------------------------\n",
    "    # ðŸ”¹ Validation Phase\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]\")\n",
    "        for batch in val_pbar:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "            ipq = batch['ipq'].to(DEVICE)\n",
    "            targets = batch['target']  # stay on CPU\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, pixel_values, ipq)\n",
    "            val_preds.extend(outputs.squeeze().cpu().numpy())\n",
    "            val_targets.extend(targets.numpy())\n",
    "\n",
    "    # Convert back from log scale\n",
    "    val_preds_orig_scale = np.expm1(val_preds)\n",
    "    val_targets_orig_scale = np.expm1(val_targets)\n",
    "\n",
    "    val_preds_orig_scale[val_preds_orig_scale < 0] = 0\n",
    "    val_smape = smape(val_targets_orig_scale, val_preds_orig_scale)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Validation SMAPE: {val_smape:.4f}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # ðŸ”¹ Checkpointing & Early Stopping\n",
    "    # -----------------------------\n",
    "    if val_smape < best_val_smape:\n",
    "        best_val_smape = val_smape\n",
    "        epochs_no_improve = 0  # reset counter\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\" New best model saved with SMAPE: {best_val_smape:.4f}%\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "    # Stop if no improvement for 'patience' epochs\n",
    "    if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"Early stopping triggered. Best SMAPE: {best_val_smape:.4f}%\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0bb980c-b843-4afd-84af-19d42d60f299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on Test Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2344/2344 [1:13:16<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file created successfully at 'test_out_01_hyper.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Inference and Submission Generation (Cell 26) ---\n",
    "print(\"Starting inference on the test set...\")\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# --- Prediction (Cell 27) ---\n",
    "test_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_pbar = tqdm(test_loader, desc=\"Predicting on Test Set\")\n",
    "    for batch in test_pbar:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        pixel_values = batch['pixel_values'].to(DEVICE)\n",
    "        ipq = batch['ipq'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, pixel_values, ipq)\n",
    "        test_predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "\n",
    "# Inverse transform predictions and ensure they are positive floats\n",
    "final_prices = np.expm1(test_predictions)\n",
    "final_prices[final_prices < 0] = 0  # Prices must be positive\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_id': test_df['sample_id'],\n",
    "    'price': final_prices.astype(float)\n",
    "})\n",
    "\n",
    "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"\\nSubmission file created successfully at '{SUBMISSION_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcf9df-8838-4db1-82ce-98c8a2af6f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
